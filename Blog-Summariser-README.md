
# 📰 Blog Summariser & Translator

**Live Demo:** [Click to Visit](https://nexium-ammar-assign2-redoo.vercel.app/)

A modern web application that simplifies content consumption by summarizing blog articles and optionally translating them into Urdu. Built with **React**, **Tailwind CSS**, and **Supabase**, the app demonstrates a full-stack implementation of web scraping, text processing, translation, and database integration.

---

## ✨ Features

- 🕵️ **Smart Blog Scraping:** Extracts readable text from any blog URL using `jsdom`.
- 🧠 **Simulated AI Summarization:** Generates a basic summary from the cleaned content.
- 🌐 **English to Urdu Translation:** Offers a basic word-to-word Urdu translation.
- 💾 **Database Storage:** Saves the blog URL and summary in **Supabase** (PostgreSQL).
- 💻 **Modern UI:** Clean and responsive interface styled with **Tailwind CSS** and inspired by **ShadCN**.
- ☁️ **Vercel Deployment:** Easily deployed with serverless functions and environment variables.

---

## 🛠️ Tech Stack

### Frontend
- **React** – UI development
- **Parcel** – Zero-config bundler
- **Tailwind CSS** – Utility-first styling

### Backend (API)
- **Node.js** & **Express.js** – For scraping endpoint
- **jsdom** – Parses HTML to extract text
- **node-fetch** – To fetch blog content

### Database
- **Supabase** – Stores blog URL & summaries
- **MongoDB (Simulated)** – Placeholder for storing full article text

### Deployment
- **Vercel** – Frontend & serverless backend deployment

---

## 🗂️ Project Structure

```
Nexium_Ammar_Assign2/
├── public/                 # HTML entry
├── src/                   # React frontend
│   └── App.jsx
├── api/                   # Vercel serverless API
│   └── scrape.js
├── server.js              # Local Express server (for dev)
├── .env                   # Supabase credentials (local only)
├── package.json           # Project config & dependencies
├── vercel.json            # Vercel config
├── README.md              # You're reading it!
└── ...
```

---

## 🚀 Getting Started (Local Setup)

### 📦 Prerequisites
- Node.js (v18+ recommended)
- pnpm (`npm install -g pnpm`)
- Git
- Supabase account

### 🔧 Setup Steps

1. **Clone the Repository**
```bash
git clone https://github.com/blackmangoo/Nexium_Ammar_Assign2.git
cd Nexium_Ammar_Assign2
```

2. **Install Dependencies**
```bash
pnpm install
```

3. **Configure Supabase**
- Create a table named `summaries` with:
  - `id` (UUID, PK, default: `gen_random_uuid()`)
  - `url` (text)
  - `summary_text` (text)
  - `full_text` (text)
  - `created_at` (timestamp, default: `now()`)

- Navigate to **Project Settings → API** to get your:
  - `SUPABASE_URL`
  - `SUPABASE_ANON_KEY`

4. **Create a `.env` File**
```env
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_anon_key
```

5. **Run the App**
```bash
pnpm run dev
```

- Frontend: [http://localhost:1234](http://localhost:1234)
- API Server: [http://localhost:3001](http://localhost:3001)

---

## ⚙️ How It Works

1. **User Inputs a Blog URL**
2. **Frontend Sends Request to /api/scrape**
3. **Backend Scrapes and Cleans the Text**
4. **Summary Generated by Extracting Initial Sentences**
5. **(Optional) Urdu Translation via Simple Dictionary**
6. **Blog URL + Summary Stored in Supabase**
7. **UI Updates to Show Results**

---

## 🌍 Deployment (Vercel)

1. **Push to GitHub**
2. **Import Project to Vercel**
3. **Add Environment Variables**
   - `SUPABASE_URL`
   - `SUPABASE_ANON_KEY`
4. **Deploy!**

---

## ⚠️ Known Limitations

- 🔸 Summarization is static and not powered by real LLMs.
- 🔸 Urdu translation is dictionary-based, not contextual.
- 🔸 MongoDB functionality is simulated (not integrated).
- 🔸 Advanced scraping for dynamic websites is not handled.
- 🔸 No user authentication or history view yet.

---

## 🛣️ Future Improvements

- Integrate **Gemini API** or **OpenAI** for real summarization.
- Use **Google Translate API** or **DeepL** for accurate Urdu translation.
- Implement **MongoDB Atlas** for full text storage.
- Add **login system** and **summary history tracking**.

---

## 📜 License

This project is open-source and licensed under the **MIT License**.
